# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mQvQ_YD6FQPbJ3x692m7b3rWIyqdeIrp
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from sklearn.metrics import roc_auc_score, roc_curve, auc
import matplotlib.pyplot as plt

df = pd.read_csv('new_data.csv' )
df

from matplotlib import pyplot as plt
df['Rating'].plot(kind='hist', bins=20, title='Rating')
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Proportion of Sentiments

import matplotlib.pyplot as plt

df['Sentiment'].value_counts().plot(kind='pie', autopct='%1.1f%%')
plt.ylabel('')
_ = plt.title('Proportion of Sentiments')

# @title Distribution of Ratings by Sentiment

import matplotlib.pyplot as plt

# Group the data by Sentiment and Rating
sentiment_groups = df.groupby(['Sentiment', 'Rating'])['Rating'].count().unstack()

# Create a bar chart
ax = sentiment_groups.plot(kind='bar', figsize=(10, 6))
plt.xlabel('Sentiment')
plt.ylabel('Count')
plt.title('Distribution of Ratings by Sentiment')
plt.xticks(rotation=0)
_ = plt.legend(title='Rating')

df['Sentiment'].replace({"Positive" : 1 , "Negative" : -1 , "Neutral" : 0} , inplace = True)

# @title Sentiment
from matplotlib import pyplot as plt
df['Sentiment'].plot(kind='hist', bins=20, title='Sentiment')
plt.gca().spines[['top', 'right',]].set_visible(False)

x = np.array(df['Review_Text'].values)
y = np.array(df['Sentiment'].values)

filtered_x = []

# Check if an element is a string, if not convert to string
for review in x:
    if not isinstance(review, str):
        review = str(review)

    review = review.lower()

    for i in review:
        punc = '''!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~'''
        if i in punc:
            review = review.replace(i, " ")
    filtered_x.append(review)

print(filtered_x)

sentences_train, sentences_test, y_train, y_test = train_test_split(filtered_x, y , test_size=0.2, random_state=42)

tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences_train)
word_index = tokenizer.word_index

# Convert sentences to sequences of integers
sequences_train = tokenizer.texts_to_sequences(sentences_train)
sequences_test = tokenizer.texts_to_sequences(sentences_test)

max_length = max(len(seq) for seq in sequences_train)
padded_sequences_train = pad_sequences(sequences_train, maxlen=max_length, padding='post')
padded_sequences_test = pad_sequences(sequences_test, maxlen=max_length, padding='post')

vocab_size = len(word_index) + 1

embedding_dim = 50

num_classes = 3
y_train = tf.keras.utils.to_categorical(y_train, num_classes)
y_test = tf.keras.utils.to_categorical(y_test, num_classes)

model = Sequential()
model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))
model.add(LSTM(128, return_sequences=True))
model.add(Dropout(0.5))
model.add(LSTM(64))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.AUC()])

model.summary()

model.fit(padded_sequences_train, y_train, epochs=20, validation_data=(padded_sequences_test, y_test))

loss, accuracy, recall, auc_metric = model.evaluate(padded_sequences_test, y_test)
print(f'Test Loss: {loss:.4f}')
print(f'Test Accuracy: {accuracy:.4f}')
print(f'Test Recall: {recall:.4f}')
print(f'Test AUC: {auc_metric:.4f}')

y_pred_prob = model.predict(padded_sequences_test)

roc_auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr')
print(f'ROC AUC Score: {roc_auc:.4f}')

fpr = dict()
tpr = dict()
roc_auc_dict = dict()
for i in range(num_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred_prob[:, i])
    roc_auc_dict[i] = auc(fpr[i], tpr[i])

plt.figure()
colors = ['blue', 'red', 'green']
for i in range(num_classes):
    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label='Class {0} ROC curve (area = {1:0.4f})'.format(i, roc_auc_dict[i]))
plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic for Multi-Class')
plt.legend(loc="lower right")
plt.show()